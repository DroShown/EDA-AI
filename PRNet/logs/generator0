----------------- Options ---------------
               batch_size: 256                           	[default: 64]
                    beta1: 0.5                           
          checkpoints_dir: ./checkpoints                 
           continue_train: False                         
                crop_size: 64                            
                 dataroot: ./sample/nctugr_dataset/      	[default: None]
             dataset_mode: aligned                       
                direction: AtoB                          
             display_freq: 100                           
                    epoch: latest                        
              epoch_count: 1                             
                 gan_mode: lsgan                         
                  gpu_ids: 0                             
                init_gain: 0.02                          
                init_type: normal                        
                 input_nc: 3                             
                  isTrain: True                          	[default: None]
             lambda_focal: 100                           
              lambda_norm: 100                           
                load_iter: 0                             	[default: 0]
                       lr: 0.0001                        
           lr_decay_iters: 50                            
                lr_policy: linear                        
         max_dataset_size: inf                           
                      mix: 0.1                           
                    model: generator                     	[default: router]
                 n_epochs: 100                           
           n_epochs_decay: 100                           
               n_layers_D: 3                             
                     name: generator0                    	[default: experiment_name]
                      ndf: 64                            
                     netD: basic                         
                     netG: unet_64                       
                      ngf: 64                            
               no_dropout: False                         
                  no_flip: False                         
                  no_html: False                         
                     norm: batch                         
              num_threads: 4                             
                output_nc: 1                             
                    phase: train                         
                pool_size: 50                            
               preprocess: none                          
               print_freq: 4000                          
             save_by_iter: False                         
          save_epoch_freq: 50                            
         save_latest_freq: 200000                        
           serial_batches: False                         
                   suffix:                               
                use_wandb: False                         
                  verbose: False                         
----------------- End -------------------
  0%|          | 0/8000 [00:00<?, ?it/s]  2%|▏         | 160/8000 [00:00<00:04, 1594.46it/s]  4%|▍         | 334/8000 [00:00<00:04, 1679.43it/s]  6%|▋         | 507/8000 [00:00<00:04, 1699.28it/s]  8%|▊         | 680/8000 [00:00<00:04, 1710.04it/s] 11%|█         | 854/8000 [00:00<00:04, 1717.38it/s] 13%|█▎        | 1027/8000 [00:00<00:04, 1719.22it/s] 15%|█▍        | 1199/8000 [00:00<00:03, 1718.20it/s] 17%|█▋        | 1371/8000 [00:00<00:03, 1677.32it/s] 19%|█▉        | 1541/8000 [00:00<00:03, 1682.91it/s] 21%|██▏       | 1712/8000 [00:01<00:03, 1690.11it/s] 24%|██▎       | 1882/8000 [00:01<00:03, 1673.01it/s] 26%|██▌       | 2054/8000 [00:01<00:03, 1684.56it/s] 28%|██▊       | 2225/8000 [00:01<00:03, 1690.26it/s] 30%|██▉       | 2395/8000 [00:01<00:03, 1688.60it/s] 32%|███▏      | 2564/8000 [00:01<00:03, 1645.93it/s] 34%|███▍      | 2729/8000 [00:01<00:03, 1604.31it/s] 36%|███▌      | 2890/8000 [00:01<00:03, 1553.57it/s] 38%|███▊      | 3046/8000 [00:01<00:03, 1522.73it/s] 40%|███▉      | 3199/8000 [00:01<00:03, 1520.33it/s] 42%|████▏     | 3352/8000 [00:02<00:03, 1518.68it/s] 44%|████▍     | 3506/8000 [00:02<00:02, 1522.51it/s] 46%|████▌     | 3663/8000 [00:02<00:02, 1534.58it/s] 48%|████▊     | 3821/8000 [00:02<00:02, 1547.52it/s] 50%|████▉     | 3976/8000 [00:02<00:02, 1467.69it/s] 52%|█████▏    | 4124/8000 [00:02<00:02, 1361.16it/s] 54%|█████▎    | 4283/8000 [00:02<00:02, 1422.73it/s] 56%|█████▌    | 4459/8000 [00:02<00:02, 1517.32it/s] 58%|█████▊    | 4636/8000 [00:02<00:02, 1588.96it/s] 60%|██████    | 4812/8000 [00:03<00:01, 1638.57it/s] 62%|██████▏   | 4985/8000 [00:03<00:01, 1663.43it/s] 64%|██████▍   | 5154/8000 [00:03<00:01, 1669.45it/s] 67%|██████▋   | 5322/8000 [00:03<00:01, 1575.14it/s] 69%|██████▊   | 5482/8000 [00:03<00:01, 1538.19it/s] 71%|███████   | 5645/8000 [00:03<00:01, 1563.19it/s] 73%|███████▎  | 5815/8000 [00:03<00:01, 1601.84it/s] 75%|███████▍  | 5988/8000 [00:03<00:01, 1638.40it/s] 77%|███████▋  | 6163/8000 [00:03<00:01, 1669.00it/s] 79%|███████▉  | 6337/8000 [00:03<00:00, 1688.50it/s] 81%|████████▏ | 6507/8000 [00:04<00:00, 1679.79it/s] 84%|████████▎ | 6681/8000 [00:04<00:00, 1695.56it/s] 86%|████████▌ | 6851/8000 [00:04<00:00, 1682.16it/s] 88%|████████▊ | 7023/8000 [00:04<00:00, 1693.22it/s] 90%|████████▉ | 7193/8000 [00:04<00:00, 1403.98it/s] 92%|█████████▏| 7364/8000 [00:04<00:00, 1482.27it/s] 94%|█████████▍| 7534/8000 [00:04<00:00, 1540.88it/s] 96%|█████████▌| 7695/8000 [00:04<00:00, 1558.73it/s] 98%|█████████▊| 7860/8000 [00:04<00:00, 1582.36it/s]100%|██████████| 8000/8000 [00:04<00:00, 1600.79it/s]dataset [AlignedDataset] was created
The number of training images = 8000
initialize network with normal
model [GeneratorModel] was created
---------- Networks initialized -------------
[Network G] Total number of parameters : 29.240 M
-----------------------------------------------
learning rate 0.0001000 -> 0.0001000

/home/test_yanjunchi/miniconda3/envs/liyang/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  "https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate", UserWarning)
End of epoch 1 / 200 	 Time Taken: 7 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 2 / 200 	 Time Taken: 5 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 3 / 200 	 Time Taken: 6 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 4, iters: 7424, time: 0.001, data: 0.306) G_norm: 4.132 G_focal: 0.229 
End of epoch 4 / 200 	 Time Taken: 7 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 5 / 200 	 Time Taken: 7 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 6 / 200 	 Time Taken: 7 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 7 / 200 	 Time Taken: 7 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 8, iters: 6656, time: 0.001, data: 0.002) G_norm: 0.968 G_focal: 0.153 
End of epoch 8 / 200 	 Time Taken: 7 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 9 / 200 	 Time Taken: 7 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 10 / 200 	 Time Taken: 7 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 11 / 200 	 Time Taken: 8 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 12, iters: 5888, time: 0.001, data: 0.002) G_norm: 0.469 G_focal: 0.105 
End of epoch 12 / 200 	 Time Taken: 9 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 13 / 200 	 Time Taken: 9 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 14 / 200 	 Time Taken: 8 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 15 / 200 	 Time Taken: 8 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 16, iters: 5120, time: 0.001, data: 0.004) G_norm: 0.336 G_focal: 0.090 
End of epoch 16 / 200 	 Time Taken: 8 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 17 / 200 	 Time Taken: 8 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 18 / 200 	 Time Taken: 8 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 19 / 200 	 Time Taken: 10 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 20, iters: 4352, time: 0.001, data: 0.005) G_norm: 0.258 G_focal: 0.065 
End of epoch 20 / 200 	 Time Taken: 8 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 21 / 200 	 Time Taken: 9 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 22 / 200 	 Time Taken: 10 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 23 / 200 	 Time Taken: 10 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 24, iters: 3584, time: 0.001, data: 0.003) G_norm: 0.214 G_focal: 0.063 
End of epoch 24 / 200 	 Time Taken: 8 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 25 / 200 	 Time Taken: 9 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 26 / 200 	 Time Taken: 9 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 27 / 200 	 Time Taken: 9 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 28, iters: 2816, time: 0.001, data: 0.002) G_norm: 0.189 G_focal: 0.043 
End of epoch 28 / 200 	 Time Taken: 9 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 29 / 200 	 Time Taken: 9 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 30 / 200 	 Time Taken: 9 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 31 / 200 	 Time Taken: 9 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 32, iters: 2048, time: 0.001, data: 0.004) G_norm: 0.183 G_focal: 0.043 
End of epoch 32 / 200 	 Time Taken: 12 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 33 / 200 	 Time Taken: 10 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 34 / 200 	 Time Taken: 9 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 35 / 200 	 Time Taken: 9 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 36, iters: 1280, time: 0.001, data: 0.002) G_norm: 0.112 G_focal: 0.022 
End of epoch 36 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 37 / 200 	 Time Taken: 10 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 38 / 200 	 Time Taken: 10 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 39 / 200 	 Time Taken: 12 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 40, iters: 512, time: 0.002, data: 0.004) G_norm: 0.084 G_focal: 0.014 
End of epoch 40 / 200 	 Time Taken: 10 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 41 / 200 	 Time Taken: 10 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 42 / 200 	 Time Taken: 10 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 43, iters: 7936, time: 0.002, data: 0.002) G_norm: 0.058 G_focal: 0.009 
End of epoch 43 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 44 / 200 	 Time Taken: 10 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 45 / 200 	 Time Taken: 10 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 46 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 47, iters: 7168, time: 0.001, data: 0.003) G_norm: 0.055 G_focal: 0.011 
End of epoch 47 / 200 	 Time Taken: 10 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 48 / 200 	 Time Taken: 13 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 49 / 200 	 Time Taken: 13 sec
learning rate 0.0001000 -> 0.0001000
saving the model at the end of epoch 50, iters 409600
End of epoch 50 / 200 	 Time Taken: 14 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 51, iters: 6400, time: 0.001, data: 0.002) G_norm: 0.047 G_focal: 0.008 
End of epoch 51 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 52 / 200 	 Time Taken: 14 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 53 / 200 	 Time Taken: 10 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 54 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 55, iters: 5632, time: 0.002, data: 0.002) G_norm: 0.037 G_focal: 0.005 
End of epoch 55 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 56 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 57 / 200 	 Time Taken: 10 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 58 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 59, iters: 4864, time: 0.002, data: 0.002) G_norm: 0.036 G_focal: 0.006 
End of epoch 59 / 200 	 Time Taken: 14 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 60 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 61 / 200 	 Time Taken: 13 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 62 / 200 	 Time Taken: 14 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 63, iters: 4096, time: 0.001, data: 0.007) G_norm: 0.042 G_focal: 0.012 
End of epoch 63 / 200 	 Time Taken: 10 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 64 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 65 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 66 / 200 	 Time Taken: 14 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 67, iters: 3328, time: 0.002, data: 0.002) G_norm: 0.027 G_focal: 0.005 
End of epoch 67 / 200 	 Time Taken: 13 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 68 / 200 	 Time Taken: 14 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 69 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 70 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 71, iters: 2560, time: 0.001, data: 0.003) G_norm: 0.018 G_focal: 0.003 
End of epoch 71 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 72 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 73 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 74 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 75, iters: 1792, time: 0.002, data: 0.002) G_norm: 0.048 G_focal: 0.010 
End of epoch 75 / 200 	 Time Taken: 14 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 76 / 200 	 Time Taken: 10 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 77 / 200 	 Time Taken: 10 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 78 / 200 	 Time Taken: 10 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 79, iters: 1024, time: 0.002, data: 0.006) G_norm: 0.020 G_focal: 0.003 
End of epoch 79 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 80 / 200 	 Time Taken: 13 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 81 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 82 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 83, iters: 256, time: 0.001, data: 0.003) G_norm: 0.018 G_focal: 0.004 
End of epoch 83 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 84 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 85 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 86, iters: 7680, time: 0.002, data: 0.007) G_norm: 0.012 G_focal: 0.002 
End of epoch 86 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 87 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 88 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 89 / 200 	 Time Taken: 12 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 90, iters: 6912, time: 0.002, data: 0.002) G_norm: 0.013 G_focal: 0.002 
End of epoch 90 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 91 / 200 	 Time Taken: 13 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 92 / 200 	 Time Taken: 13 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 93 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 94, iters: 6144, time: 0.002, data: 0.005) G_norm: 0.016 G_focal: 0.004 
End of epoch 94 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 95 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 96 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 97 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0001000
(epoch: 98, iters: 5376, time: 0.002, data: 0.002) G_norm: 0.016 G_focal: 0.004 
saving the latest model (epoch 98, total_iters 800000)
End of epoch 98 / 200 	 Time Taken: 12 sec
learning rate 0.0001000 -> 0.0001000
End of epoch 99 / 200 	 Time Taken: 11 sec
learning rate 0.0001000 -> 0.0000990
saving the model at the end of epoch 100, iters 819200
End of epoch 100 / 200 	 Time Taken: 15 sec
learning rate 0.0000990 -> 0.0000980
End of epoch 101 / 200 	 Time Taken: 11 sec
learning rate 0.0000980 -> 0.0000970
(epoch: 102, iters: 4608, time: 0.002, data: 0.004) G_norm: 0.019 G_focal: 0.004 
End of epoch 102 / 200 	 Time Taken: 11 sec
learning rate 0.0000970 -> 0.0000960
End of epoch 103 / 200 	 Time Taken: 13 sec
learning rate 0.0000960 -> 0.0000950
End of epoch 104 / 200 	 Time Taken: 11 sec
learning rate 0.0000950 -> 0.0000941
End of epoch 105 / 200 	 Time Taken: 11 sec
learning rate 0.0000941 -> 0.0000931
(epoch: 106, iters: 3840, time: 0.002, data: 0.002) G_norm: 0.011 G_focal: 0.002 
End of epoch 106 / 200 	 Time Taken: 11 sec
learning rate 0.0000931 -> 0.0000921
End of epoch 107 / 200 	 Time Taken: 14 sec
learning rate 0.0000921 -> 0.0000911
End of epoch 108 / 200 	 Time Taken: 11 sec
learning rate 0.0000911 -> 0.0000901
End of epoch 109 / 200 	 Time Taken: 11 sec
learning rate 0.0000901 -> 0.0000891
(epoch: 110, iters: 3072, time: 0.002, data: 0.006) G_norm: 0.009 G_focal: 0.001 
End of epoch 110 / 200 	 Time Taken: 11 sec
learning rate 0.0000891 -> 0.0000881
End of epoch 111 / 200 	 Time Taken: 11 sec
learning rate 0.0000881 -> 0.0000871
End of epoch 112 / 200 	 Time Taken: 11 sec
learning rate 0.0000871 -> 0.0000861
End of epoch 113 / 200 	 Time Taken: 11 sec
learning rate 0.0000861 -> 0.0000851
(epoch: 114, iters: 2304, time: 0.002, data: 0.003) G_norm: 0.012 G_focal: 0.002 
End of epoch 114 / 200 	 Time Taken: 11 sec
learning rate 0.0000851 -> 0.0000842
End of epoch 115 / 200 	 Time Taken: 11 sec
learning rate 0.0000842 -> 0.0000832
End of epoch 116 / 200 	 Time Taken: 15 sec
learning rate 0.0000832 -> 0.0000822
End of epoch 117 / 200 	 Time Taken: 14 sec
learning rate 0.0000822 -> 0.0000812
(epoch: 118, iters: 1536, time: 0.002, data: 0.002) G_norm: 0.010 G_focal: 0.002 
End of epoch 118 / 200 	 Time Taken: 14 sec
learning rate 0.0000812 -> 0.0000802
End of epoch 119 / 200 	 Time Taken: 11 sec
learning rate 0.0000802 -> 0.0000792
End of epoch 120 / 200 	 Time Taken: 11 sec
learning rate 0.0000792 -> 0.0000782
End of epoch 121 / 200 	 Time Taken: 11 sec
learning rate 0.0000782 -> 0.0000772
(epoch: 122, iters: 768, time: 0.002, data: 0.002) G_norm: 0.015 G_focal: 0.003 
End of epoch 122 / 200 	 Time Taken: 11 sec
learning rate 0.0000772 -> 0.0000762
End of epoch 123 / 200 	 Time Taken: 11 sec
learning rate 0.0000762 -> 0.0000752
End of epoch 124 / 200 	 Time Taken: 11 sec
learning rate 0.0000752 -> 0.0000743
(epoch: 125, iters: 8192, time: 0.001, data: 0.008) G_norm: 0.012 G_focal: 0.002 
End of epoch 125 / 200 	 Time Taken: 11 sec
learning rate 0.0000743 -> 0.0000733
End of epoch 126 / 200 	 Time Taken: 11 sec
learning rate 0.0000733 -> 0.0000723
End of epoch 127 / 200 	 Time Taken: 11 sec
learning rate 0.0000723 -> 0.0000713
End of epoch 128 / 200 	 Time Taken: 10 sec
learning rate 0.0000713 -> 0.0000703
(epoch: 129, iters: 7424, time: 0.002, data: 0.405) G_norm: 0.017 G_focal: 0.004 
End of epoch 129 / 200 	 Time Taken: 11 sec
learning rate 0.0000703 -> 0.0000693
End of epoch 130 / 200 	 Time Taken: 11 sec
learning rate 0.0000693 -> 0.0000683
End of epoch 131 / 200 	 Time Taken: 11 sec
learning rate 0.0000683 -> 0.0000673
End of epoch 132 / 200 	 Time Taken: 11 sec
learning rate 0.0000673 -> 0.0000663
(epoch: 133, iters: 6656, time: 0.001, data: 0.002) G_norm: 0.009 G_focal: 0.002 
End of epoch 133 / 200 	 Time Taken: 11 sec
learning rate 0.0000663 -> 0.0000653
End of epoch 134 / 200 	 Time Taken: 12 sec
learning rate 0.0000653 -> 0.0000644
End of epoch 135 / 200 	 Time Taken: 15 sec
learning rate 0.0000644 -> 0.0000634
End of epoch 136 / 200 	 Time Taken: 11 sec
learning rate 0.0000634 -> 0.0000624
(epoch: 137, iters: 5888, time: 0.001, data: 0.002) G_norm: 0.013 G_focal: 0.002 
End of epoch 137 / 200 	 Time Taken: 11 sec
learning rate 0.0000624 -> 0.0000614
End of epoch 138 / 200 	 Time Taken: 11 sec
learning rate 0.0000614 -> 0.0000604
End of epoch 139 / 200 	 Time Taken: 11 sec
learning rate 0.0000604 -> 0.0000594
End of epoch 140 / 200 	 Time Taken: 11 sec
learning rate 0.0000594 -> 0.0000584
(epoch: 141, iters: 5120, time: 0.002, data: 0.006) G_norm: 0.012 G_focal: 0.002 
End of epoch 141 / 200 	 Time Taken: 11 sec
learning rate 0.0000584 -> 0.0000574
End of epoch 142 / 200 	 Time Taken: 11 sec
learning rate 0.0000574 -> 0.0000564
End of epoch 143 / 200 	 Time Taken: 11 sec
learning rate 0.0000564 -> 0.0000554
End of epoch 144 / 200 	 Time Taken: 11 sec
learning rate 0.0000554 -> 0.0000545
(epoch: 145, iters: 4352, time: 0.002, data: 0.002) G_norm: 0.013 G_focal: 0.002 
End of epoch 145 / 200 	 Time Taken: 11 sec
learning rate 0.0000545 -> 0.0000535
End of epoch 146 / 200 	 Time Taken: 14 sec
learning rate 0.0000535 -> 0.0000525
End of epoch 147 / 200 	 Time Taken: 11 sec
learning rate 0.0000525 -> 0.0000515
End of epoch 148 / 200 	 Time Taken: 15 sec
learning rate 0.0000515 -> 0.0000505
(epoch: 149, iters: 3584, time: 0.001, data: 0.002) G_norm: 0.011 G_focal: 0.003 
End of epoch 149 / 200 	 Time Taken: 11 sec
learning rate 0.0000505 -> 0.0000495
saving the model at the end of epoch 150, iters 1228800
End of epoch 150 / 200 	 Time Taken: 12 sec
learning rate 0.0000495 -> 0.0000485
End of epoch 151 / 200 	 Time Taken: 11 sec
learning rate 0.0000485 -> 0.0000475
End of epoch 152 / 200 	 Time Taken: 11 sec
learning rate 0.0000475 -> 0.0000465
(epoch: 153, iters: 2816, time: 0.002, data: 0.002) G_norm: 0.011 G_focal: 0.002 
End of epoch 153 / 200 	 Time Taken: 11 sec
learning rate 0.0000465 -> 0.0000455
End of epoch 154 / 200 	 Time Taken: 11 sec
learning rate 0.0000455 -> 0.0000446
End of epoch 155 / 200 	 Time Taken: 14 sec
learning rate 0.0000446 -> 0.0000436
End of epoch 156 / 200 	 Time Taken: 11 sec
learning rate 0.0000436 -> 0.0000426
(epoch: 157, iters: 2048, time: 0.002, data: 0.007) G_norm: 0.012 G_focal: 0.002 
End of epoch 157 / 200 	 Time Taken: 15 sec
learning rate 0.0000426 -> 0.0000416
End of epoch 158 / 200 	 Time Taken: 11 sec
learning rate 0.0000416 -> 0.0000406
End of epoch 159 / 200 	 Time Taken: 11 sec
learning rate 0.0000406 -> 0.0000396
End of epoch 160 / 200 	 Time Taken: 11 sec
learning rate 0.0000396 -> 0.0000386
(epoch: 161, iters: 1280, time: 0.002, data: 0.002) G_norm: 0.007 G_focal: 0.001 
End of epoch 161 / 200 	 Time Taken: 14 sec
learning rate 0.0000386 -> 0.0000376
End of epoch 162 / 200 	 Time Taken: 14 sec
learning rate 0.0000376 -> 0.0000366
End of epoch 163 / 200 	 Time Taken: 11 sec
learning rate 0.0000366 -> 0.0000356
End of epoch 164 / 200 	 Time Taken: 11 sec
learning rate 0.0000356 -> 0.0000347
(epoch: 165, iters: 512, time: 0.001, data: 0.002) G_norm: 0.018 G_focal: 0.004 
End of epoch 165 / 200 	 Time Taken: 11 sec
learning rate 0.0000347 -> 0.0000337
End of epoch 166 / 200 	 Time Taken: 13 sec
learning rate 0.0000337 -> 0.0000327
End of epoch 167 / 200 	 Time Taken: 11 sec
learning rate 0.0000327 -> 0.0000317
(epoch: 168, iters: 7936, time: 0.002, data: 0.002) G_norm: 0.011 G_focal: 0.002 
End of epoch 168 / 200 	 Time Taken: 11 sec
learning rate 0.0000317 -> 0.0000307
End of epoch 169 / 200 	 Time Taken: 11 sec
learning rate 0.0000307 -> 0.0000297
End of epoch 170 / 200 	 Time Taken: 13 sec
learning rate 0.0000297 -> 0.0000287
End of epoch 171 / 200 	 Time Taken: 13 sec
learning rate 0.0000287 -> 0.0000277
(epoch: 172, iters: 7168, time: 0.002, data: 0.003) G_norm: 0.017 G_focal: 0.004 
End of epoch 172 / 200 	 Time Taken: 11 sec
learning rate 0.0000277 -> 0.0000267
End of epoch 173 / 200 	 Time Taken: 12 sec
learning rate 0.0000267 -> 0.0000257
End of epoch 174 / 200 	 Time Taken: 11 sec
learning rate 0.0000257 -> 0.0000248
End of epoch 175 / 200 	 Time Taken: 11 sec
learning rate 0.0000248 -> 0.0000238
(epoch: 176, iters: 6400, time: 0.002, data: 0.002) G_norm: 0.008 G_focal: 0.001 
End of epoch 176 / 200 	 Time Taken: 14 sec
learning rate 0.0000238 -> 0.0000228
End of epoch 177 / 200 	 Time Taken: 12 sec
learning rate 0.0000228 -> 0.0000218
End of epoch 178 / 200 	 Time Taken: 11 sec
learning rate 0.0000218 -> 0.0000208
End of epoch 179 / 200 	 Time Taken: 11 sec
learning rate 0.0000208 -> 0.0000198
(epoch: 180, iters: 5632, time: 0.002, data: 0.002) G_norm: 0.008 G_focal: 0.002 
End of epoch 180 / 200 	 Time Taken: 14 sec
learning rate 0.0000198 -> 0.0000188
End of epoch 181 / 200 	 Time Taken: 11 sec
learning rate 0.0000188 -> 0.0000178
End of epoch 182 / 200 	 Time Taken: 11 sec
learning rate 0.0000178 -> 0.0000168
End of epoch 183 / 200 	 Time Taken: 14 sec
learning rate 0.0000168 -> 0.0000158
(epoch: 184, iters: 4864, time: 0.001, data: 0.002) G_norm: 0.009 G_focal: 0.002 
End of epoch 184 / 200 	 Time Taken: 11 sec
learning rate 0.0000158 -> 0.0000149
End of epoch 185 / 200 	 Time Taken: 11 sec
learning rate 0.0000149 -> 0.0000139
End of epoch 186 / 200 	 Time Taken: 11 sec
learning rate 0.0000139 -> 0.0000129
End of epoch 187 / 200 	 Time Taken: 12 sec
learning rate 0.0000129 -> 0.0000119
(epoch: 188, iters: 4096, time: 0.002, data: 0.008) G_norm: 0.012 G_focal: 0.002 
End of epoch 188 / 200 	 Time Taken: 11 sec
learning rate 0.0000119 -> 0.0000109
End of epoch 189 / 200 	 Time Taken: 15 sec
learning rate 0.0000109 -> 0.0000099
End of epoch 190 / 200 	 Time Taken: 14 sec
learning rate 0.0000099 -> 0.0000089
End of epoch 191 / 200 	 Time Taken: 14 sec
learning rate 0.0000089 -> 0.0000079
(epoch: 192, iters: 3328, time: 0.002, data: 0.006) G_norm: 0.004 G_focal: 0.001 
End of epoch 192 / 200 	 Time Taken: 14 sec
learning rate 0.0000079 -> 0.0000069
End of epoch 193 / 200 	 Time Taken: 14 sec
learning rate 0.0000069 -> 0.0000059
End of epoch 194 / 200 	 Time Taken: 11 sec
learning rate 0.0000059 -> 0.0000050
End of epoch 195 / 200 	 Time Taken: 11 sec
learning rate 0.0000050 -> 0.0000040
(epoch: 196, iters: 2560, time: 0.002, data: 0.002) G_norm: 0.009 G_focal: 0.002 
saving the latest model (epoch 196, total_iters 1600000)
End of epoch 196 / 200 	 Time Taken: 15 sec
learning rate 0.0000040 -> 0.0000030
End of epoch 197 / 200 	 Time Taken: 15 sec
learning rate 0.0000030 -> 0.0000020
End of epoch 198 / 200 	 Time Taken: 11 sec
learning rate 0.0000020 -> 0.0000010
End of epoch 199 / 200 	 Time Taken: 11 sec
learning rate 0.0000010 -> 0.0000000
(epoch: 200, iters: 1792, time: 0.002, data: 0.003) G_norm: 0.011 G_focal: 0.002 
saving the model at the end of epoch 200, iters 1638400
End of epoch 200 / 200 	 Time Taken: 12 sec
Correctness:  [0.0, 0.0, 0.170625, 0.212375, 0.31275, 0.487, 0.4935, 0.493625, 0.497875, 0.562125, 0.60175, 0.63825, 0.68025, 0.690375, 0.690625, 0.696875, 0.711, 0.733875, 0.7435, 0.756, 0.75575, 0.769625, 0.77025, 0.774875, 0.777125, 0.7825, 0.782125, 0.792375, 0.80025, 0.79275, 0.79825, 0.809375, 0.803625, 0.811875, 0.814125, 0.819, 0.819625, 0.83, 0.828375, 0.839375, 0.8445, 0.85125, 0.855875, 0.8585, 0.870125, 0.8775, 0.88225, 0.885875, 0.897875, 0.888375, 0.900125, 0.910125, 0.920375, 0.926375, 0.920375, 0.928125, 0.92775, 0.939125, 0.944125, 0.94, 0.9465, 0.952375, 0.93925, 0.960375, 0.957375, 0.96075, 0.959, 0.95225, 0.96375, 0.964375, 0.96475, 0.96625, 0.968375, 0.9525, 0.943625, 0.85, 0.8835, 0.93725, 0.961625, 0.965625, 0.965125, 0.973625, 0.9735, 0.974875, 0.976, 0.976875, 0.978875, 0.977875, 0.981125, 0.977625, 0.97975, 0.978875, 0.975625, 0.9795, 0.98125, 0.977625, 0.980125, 0.97925, 0.98175, 0.979, 0.9705, 0.97875, 0.982625, 0.9845, 0.984625, 0.979625, 0.979625, 0.977125, 0.9815, 0.981375, 0.977875, 0.98525, 0.981125, 0.980875, 0.981375, 0.981875, 0.984125, 0.9825, 0.979875, 0.98125, 0.980625, 0.983, 0.982125, 0.979875, 0.9785, 0.981125, 0.98175, 0.986125, 0.98225, 0.980375, 0.978875, 0.983, 0.98275, 0.98275, 0.978, 0.9835, 0.98375, 0.984, 0.983375, 0.981625, 0.98175, 0.9775, 0.985375, 0.982375, 0.97875, 0.982125, 0.981875, 0.9795, 0.984625, 0.983375, 0.986, 0.98225, 0.984625, 0.98525, 0.98275, 0.98725, 0.98275, 0.986125, 0.983125, 0.981875, 0.98425, 0.985, 0.98125, 0.981, 0.981625, 0.9805, 0.978125, 0.978625, 0.98275, 0.984, 0.982625, 0.984125, 0.983125, 0.98575, 0.98325, 0.98025, 0.98275, 0.982625, 0.98125, 0.984, 0.98275, 0.98075, 0.982375, 0.980125, 0.98325, 0.981875, 0.98175, 0.983875, 0.981875, 0.985375, 0.982, 0.979875, 0.983875, 0.979, 0.979, 0.981875, 0.978125, 0.98075, 0.977375, 0.977875]
WL ratio:  [0.0, 0.0, 0.9999633713050804, 0.9999705717901181, 0.999980016386563, 0.9999873001358885, 0.9999875079636731, 0.9999875126434484, 1.0041799731199368, 1.0116151068404646, 1.0136193804989755, 1.0239591951621019, 1.032542567290031, 1.0256410256410255, 1.0239723753237266, 1.0221877446649572, 1.022044642301657, 1.0249608260024317, 1.0219701801693706, 1.0193180644259576, 1.0166952945301961, 1.0157556107198946, 1.0172061696487373, 1.0134111167239723, 1.0146949155270373, 1.015058059946829, 1.0121854428311312, 1.013132635030884, 1.011716821045386, 1.0145007554045304, 1.0143848586746345, 1.0120315859464863, 1.0160490054854716, 1.0136715107521483, 1.0145775621634632, 1.0143055600726663, 1.0176070919855649, 1.0148355859148317, 1.012475860589155, 1.0129057654782414, 1.014304984399408, 1.0151763171767056, 1.0144185111774002, 1.0128979133384688, 1.0119303002224538, 1.0128245686613293, 1.012605451714967, 1.0113840077303238, 1.0098717518676077, 1.0116435303418234, 1.0108498589736015, 1.0098667578965852, 1.0076953790383505, 1.008566089111004, 1.007165365393493, 1.007949196570322, 1.0087304443905012, 1.006285773920862, 1.0060584339778271, 1.0063494012239746, 1.006631337988468, 1.0055595842397873, 1.0063550475348935, 1.0048414238175851, 1.0045369602114391, 1.004824020050226, 1.004764895659127, 1.0055382798967432, 1.0035007294228926, 1.0038124827017014, 1.0052816857731877, 1.0041506828106685, 1.004615031322457, 1.00524577726622, 1.0061012339002653, 1.0160948442069677, 1.0209962803383805, 1.0099743243586021, 1.0053838625736835, 1.005516693679902, 1.004748081640001, 1.003430302056477, 1.0040503819664006, 1.0035441783409165, 1.0025863674964495, 1.0028987189064649, 1.0032780874687328, 1.0039755919388786, 1.0027628095536945, 1.002901524812998, 1.0033835949675929, 1.0027615479088905, 1.0027537286549764, 1.00264258285423, 1.0023745441187417, 1.0033074743121106, 1.0027842439180246, 1.0027914190958114, 1.0029478713682296, 1.003462705530463, 1.0034408257981915, 1.0029322550460527, 1.0022745739068744, 1.0037456044651234, 1.0028415676658757, 1.0026952749589928, 1.0027821720145662, 1.0025514321991227, 1.002490824225483, 1.0038296557620872, 1.0022324700635137, 1.0034079716487285, 1.002369764772692, 1.0030214235488648, 1.0019621419210782, 1.0024175713590873, 1.0026730622687348, 1.0035096437556295, 1.0026348534287859, 1.0030956480807702, 1.002107554828794, 1.0030556345279535, 1.0031549665009054, 1.002658828437237, 1.0027537381576077, 1.002465314297625, 1.0029693644984794, 1.0027638604381637, 1.0031811686306613, 1.0024905853954373, 1.0025423057440745, 1.0033892961298967, 1.0031316463751612, 1.0026542466750117, 1.0029529001612203, 1.0031747851824249, 1.0024818400491113, 1.0032728411560374, 1.0030554155389022, 1.0024403035651424, 1.0027346216546502, 1.0047682862218343, 1.002480299641204, 1.0023938980760152, 1.003971360244745, 1.003467909274324, 1.0027995239132985, 1.0023472096017416, 1.0042655056734326, 1.0033652502680974, 1.0022171255647228, 1.0029395514373665, 1.0036440247765086, 1.002358574934239, 1.0039661384060379, 1.0028075372492804, 1.0027466945240617, 1.003144586614408, 1.0027967109339675, 1.0031083917004266, 1.003199514457552, 1.0028341171450978, 1.002723896391495, 1.003301878886412, 1.0027734504930712, 1.0032281917579406, 1.003142246045787, 1.0031610910197695, 1.0032943065114512, 1.0031024525854966, 1.0030578261462066, 1.0030314540229472, 1.0031751644324245, 1.0036216593828158, 1.0035306671504722, 1.0039462883590478, 1.0033930240954925, 1.0035563219653636, 1.0046560962849178, 1.0030810711323475, 1.0025119070139437, 1.0039685102657394, 1.0037482889025326, 1.0046630029356105, 1.0032468385731113, 1.0032660481294777, 1.003388567703296, 1.0031728145419474, 1.003605209276545, 1.0034550097641581, 1.0031024525854966, 1.0034934309610408, 1.0048164201998613, 1.0036833073658968, 1.0034967800383952, 1.0045369731054734, 1.0038119136094192, 1.0042275972000831, 1.0032846986786825, 1.0039752618425184]
D real:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
D fake:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
GAN loss:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
